# final calculation, which gives you theta bar!
2 * theta_hat - bias
}
tic()
phenesse::weib_percentile(testobservations, percentile = 0, iterations = 200)
toc()
tic()
dl_code(testobservations, percentile = 0, iterations = 200)
toc
tic()
dl_code(testobservations, percentile = 0, iterations = 200)
toc()
tic()
phenesse::weib_percentile(testobservations, percentile = 0, iterations = 500)
toc()
tic()
dl_code(testobservations, percentile = 0, iterations = 500)
toc()
install.packages("devtools")
install.packages("roxygen2")
library(roxygen2)
library(devtools)
document()
build()
release()
spell_check()
release()
check()
release()
check_rhub()
r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
mean_ci(observations = r_hirta$doy , bootstraps = 100)
release()
check_win_devel()
r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
View(r_hirta)
mean_ci(observations = r_hirta$doy , bootstraps = 100)
mean_ci(observations = r_hirta$doy , bootstraps = 500)
s_cybele <- subset(inat_examples, scientific_name == "Speyeria cybele")
quantile_ci(observations = s_cybele$doy, percentile = 0.1, bootstraps = 100)
testobs <- rnorm(20, mean = 150, sd = 20)
#' a_syriaca <- subset(inat_examples, scientific_name == "Asclepias syriaca")
#' weib_percentile(a_syriaca$doy, percentile = 0.5, iterations = 10)
#'
#' # Estimate when 90 percent of individuals of the milkweed species A. syriaca
#' # have been observed, using only 10 iterations for quicker processing. To get
#' # more stable result, more observations should be used.
#'
#' weib_percentile(a_syriaca$doy, percentile = 0.5, iterations = 10)
#' }
#'
weib_percentile <- function(observations, percentile = 0.9, iterations = 500){
# curve_intersect determines where two lines intersect
# parameters needed are two dataframes with two columns, x and y, which could
# be plotted.
curve_intersect <- function(curve1, curve2, empirical=TRUE, domain=NULL) {
if (!empirical & missing(domain)) {
stop("'domain' must be provided with non-empirical curves")
}
if (!empirical & (length(domain) != 2 | !is.numeric(domain))) {
stop("'domain' must be a two-value numeric vector, like c(0, 10)")
}
if (empirical) {
# Approximate the functional form of both curves
curve1_f <- stats::approxfun(curve1$x, curve1$y, rule = 2)
curve2_f <- suppressWarnings(stats::approxfun(curve2$x, curve2$y, rule = 2))
# Calculate the intersection of curve 1 and curve 2 along the x-axis
point_x <- stats::uniroot(function(x) curve1_f(x) - curve2_f(x),
c(min(curve1$x), max(curve1$x)))$root
# Find where point_x is in curve 2
point_y <- curve2_f(point_x)
} else {
# Calculate the intersection of curve 1 and curve 2 along the x-axis
# within the given domain
point_x <- stats::uniroot(function(x) curve1(x) - curve2(x), domain)$root
# Find where point_x is in curve 2
point_y <- curve2(point_x)
}
return(list(x = point_x, y = point_y))
}
# use a data frame to plot a smooth CDF from -0.001 to 1.001 given
# our original observations
create_predict_df <- function(observations){
# previous create_cdf_ends()
weib <- fitdistrplus::fitdist(observations, distr = "weibull",
method = "mle")
cdf0 <- as.numeric(weib$estimate['scale']*
(-log(1-0.01))^(1/weib$estimate['shape']))
cdf100 <- as.numeric(weib$estimate['scale']*
(-log(1-0.99))^(1/weib$estimate['shape']))
added_vec <- sort(append(observations, values = c(cdf0, cdf100)),
decreasing = FALSE)
new_vec <- seq(from = min(added_vec), to = max(added_vec), by = 0.5)
cdfadded <- 1 - exp(-(new_vec/weib$estimate['scale'])^weib$estimate['shape'])
cdf_df <- data.frame(x = new_vec, y = cdfadded)
ends <- data.frame(x = c(min(added_vec - 1), max(added_vec + 1)),
y = c(-0.001,1.001))
cdf_df <- rbind(cdf_df, ends)
cdf_df <- cdf_df[order(cdf_df$x, decreasing = FALSE),]
return(cdf_df)
}
# calculates the theta hat value for each iteration, which
# when averaged is used to calculate the bias value
get_theta_hat_i <- function(observations, percentile){
emptyvec <- vector(mode = "numeric", length = length(observations))
df1 <- create_predict_df(observations) # move out of loop since constant
for(i in seq_along(observations)){
sim_vector <- stats::runif(n = 1, min = 0, max = 1)
df2 <- data.frame(x = observations, y = sim_vector)
emptyvec[i] <- curve_intersect(df1, df2)$x
}
new_vector <- sort(emptyvec, decreasing = FALSE)
new_df1 <- create_predict_df(new_vector)
new_df2 <- data.frame(x = observations, y = percentile)
theta_hat_i <- curve_intersect(new_df1, new_df2)$x
return(theta_hat_i)
}
theta_hat_df <- data.frame(x = observations, y = percentile)
# calculate theta hat original value
theta_hat <- curve_intersect(curve1 = create_predict_df(observations),
curve2 = theta_hat_df)[['x']]
# calculate bias value based off of the mean of many theta hat i calculations
bias <- mean(replicate(n = iterations,
expr = get_theta_hat_i(observations = observations,
percentile = percentile)))
# final calculation, which gives you theta bar!
2 * theta_hat - bias
}
a <- weib_percentile(testobs)
#' a_syriaca <- subset(inat_examples, scientific_name == "Asclepias syriaca")
#' weib_percentile(a_syriaca$doy, percentile = 0.5, iterations = 10)
#'
#' # Estimate when 90 percent of individuals of the milkweed species A. syriaca
#' # have been observed, using only 10 iterations for quicker processing. To get
#' # more stable result, more observations should be used.
#'
#' weib_percentile(a_syriaca$doy, percentile = 0.5, iterations = 10)
#' }
#'
weib_percentile <- function(observations, iterations = 500){
# curve_intersect determines where two lines intersect
# parameters needed are two dataframes with two columns, x and y, which could
# be plotted.
curve_intersect <- function(curve1, curve2, empirical=TRUE, domain=NULL) {
if (!empirical & missing(domain)) {
stop("'domain' must be provided with non-empirical curves")
}
if (!empirical & (length(domain) != 2 | !is.numeric(domain))) {
stop("'domain' must be a two-value numeric vector, like c(0, 10)")
}
if (empirical) {
# Approximate the functional form of both curves
curve1_f <- stats::approxfun(curve1$x, curve1$y, rule = 2)
curve2_f <- suppressWarnings(stats::approxfun(curve2$x, curve2$y, rule = 2))
# Calculate the intersection of curve 1 and curve 2 along the x-axis
point_x <- stats::uniroot(function(x) curve1_f(x) - curve2_f(x),
c(min(curve1$x), max(curve1$x)))$root
# Find where point_x is in curve 2
point_y <- curve2_f(point_x)
} else {
# Calculate the intersection of curve 1 and curve 2 along the x-axis
# within the given domain
point_x <- stats::uniroot(function(x) curve1(x) - curve2(x), domain)$root
# Find where point_x is in curve 2
point_y <- curve2(point_x)
}
return(list(x = point_x, y = point_y))
}
# use a data frame to plot a smooth CDF from -0.001 to 1.001 given
# our original observations
create_predict_df <- function(observations){
# previous create_cdf_ends()
weib <- fitdistrplus::fitdist(observations, distr = "weibull",
method = "mle")
cdf0 <- as.numeric(weib$estimate['scale']*
(-log(1-0.01))^(1/weib$estimate['shape']))
cdf100 <- as.numeric(weib$estimate['scale']*
(-log(1-0.99))^(1/weib$estimate['shape']))
added_vec <- sort(append(observations, values = c(cdf0, cdf100)),
decreasing = FALSE)
new_vec <- seq(from = min(added_vec), to = max(added_vec), by = 0.5)
cdfadded <- 1 - exp(-(new_vec/weib$estimate['scale'])^weib$estimate['shape'])
cdf_df <- data.frame(x = new_vec, y = cdfadded)
ends <- data.frame(x = c(min(added_vec - 1), max(added_vec + 1)),
y = c(-0.001,1.001))
cdf_df <- rbind(cdf_df, ends)
cdf_df <- cdf_df[order(cdf_df$x, decreasing = FALSE),]
return(cdf_df)
}
# calculates the theta hat value for each iteration, which
# when averaged is used to calculate the bias value
get_theta_hat_i <- function(observations, percentile){
emptyvec <- vector(mode = "numeric", length = length(observations))
df1 <- create_predict_df(observations) # move out of loop since constant
for(i in seq_along(observations)){
sim_vector <- stats::runif(n = 1, min = 0, max = 1)
df2 <- data.frame(x = observations, y = sim_vector)
emptyvec[i] <- curve_intersect(df1, df2)$x
}
new_vector <- sort(emptyvec, decreasing = FALSE)
new_df1 <- create_predict_df(new_vector)
new_df2 <- data.frame(x = observations, y = percentile)
theta_hat_i <- curve_intersect(new_df1, new_df2)$x
return(theta_hat_i)
}
theta_hat_df <- data.frame(x = observations, y = percentile)
# calculate theta hat original value
theta_hat <- curve_intersect(curve1 = create_predict_df(observations),
curve2 = theta_hat_df)[['x']]
# calculate bias value based off of the mean of many theta hat i calculations
bias <- mean(replicate(n = iterations,
expr = get_theta_hat_i(observations = observations,
percentile = percentile)))
# final calculation, which gives you theta bar!
2 * theta_hat - bias
}
a <- weib_percentile(testobs)
#' a_syriaca <- subset(inat_examples, scientific_name == "Asclepias syriaca")
#' weib_percentile(a_syriaca$doy, percentile = 0.5, iterations = 10)
#'
#' # Estimate when 90 percent of individuals of the milkweed species A. syriaca
#' # have been observed, using only 10 iterations for quicker processing. To get
#' # more stable result, more observations should be used.
#'
#' weib_percentile(a_syriaca$doy, percentile = 0.5, iterations = 10)
#' }
#'
weib_percentile <- function(observations, percentile, iterations = 500){
# curve_intersect determines where two lines intersect
# parameters needed are two dataframes with two columns, x and y, which could
# be plotted.
curve_intersect <- function(curve1, curve2, empirical=TRUE, domain=NULL) {
if (!empirical & missing(domain)) {
stop("'domain' must be provided with non-empirical curves")
}
if (!empirical & (length(domain) != 2 | !is.numeric(domain))) {
stop("'domain' must be a two-value numeric vector, like c(0, 10)")
}
if (empirical) {
# Approximate the functional form of both curves
curve1_f <- stats::approxfun(curve1$x, curve1$y, rule = 2)
curve2_f <- suppressWarnings(stats::approxfun(curve2$x, curve2$y, rule = 2))
# Calculate the intersection of curve 1 and curve 2 along the x-axis
point_x <- stats::uniroot(function(x) curve1_f(x) - curve2_f(x),
c(min(curve1$x), max(curve1$x)))$root
# Find where point_x is in curve 2
point_y <- curve2_f(point_x)
} else {
# Calculate the intersection of curve 1 and curve 2 along the x-axis
# within the given domain
point_x <- stats::uniroot(function(x) curve1(x) - curve2(x), domain)$root
# Find where point_x is in curve 2
point_y <- curve2(point_x)
}
return(list(x = point_x, y = point_y))
}
# use a data frame to plot a smooth CDF from -0.001 to 1.001 given
# our original observations
create_predict_df <- function(observations){
# previous create_cdf_ends()
weib <- fitdistrplus::fitdist(observations, distr = "weibull",
method = "mle")
cdf0 <- as.numeric(weib$estimate['scale']*
(-log(1-0.01))^(1/weib$estimate['shape']))
cdf100 <- as.numeric(weib$estimate['scale']*
(-log(1-0.99))^(1/weib$estimate['shape']))
added_vec <- sort(append(observations, values = c(cdf0, cdf100)),
decreasing = FALSE)
new_vec <- seq(from = min(added_vec), to = max(added_vec), by = 0.5)
cdfadded <- 1 - exp(-(new_vec/weib$estimate['scale'])^weib$estimate['shape'])
cdf_df <- data.frame(x = new_vec, y = cdfadded)
ends <- data.frame(x = c(min(added_vec - 1), max(added_vec + 1)),
y = c(-0.001,1.001))
cdf_df <- rbind(cdf_df, ends)
cdf_df <- cdf_df[order(cdf_df$x, decreasing = FALSE),]
return(cdf_df)
}
# calculates the theta hat value for each iteration, which
# when averaged is used to calculate the bias value
get_theta_hat_i <- function(observations, percentile){
emptyvec <- vector(mode = "numeric", length = length(observations))
df1 <- create_predict_df(observations) # move out of loop since constant
for(i in seq_along(observations)){
sim_vector <- stats::runif(n = 1, min = 0, max = 1)
df2 <- data.frame(x = observations, y = sim_vector)
emptyvec[i] <- curve_intersect(df1, df2)$x
}
new_vector <- sort(emptyvec, decreasing = FALSE)
new_df1 <- create_predict_df(new_vector)
new_df2 <- data.frame(x = observations, y = percentile)
theta_hat_i <- curve_intersect(new_df1, new_df2)$x
return(theta_hat_i)
}
theta_hat_df <- data.frame(x = observations, y = percentile)
# calculate theta hat original value
theta_hat <- curve_intersect(curve1 = create_predict_df(observations),
curve2 = theta_hat_df)[['x']]
# calculate bias value based off of the mean of many theta hat i calculations
bias <- mean(replicate(n = iterations,
expr = get_theta_hat_i(observations = observations,
percentile = percentile)))
# final calculation, which gives you theta bar!
2 * theta_hat - bias
}
a <- weib_percentile(testobs)
a <- weib_percentile(testobs, percentile = 0)
tic()
a <- weib_percentile(testobs, percentile = 0)
toc()
library(tictoc)
tic()
a <- weib_percentile(testobs, percentile = 0)
toc()
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/GitHub/phenesse/R/weib_percentile.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
a
#' # to October
#'
#' r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
#' mean_ci(observations = r_hirta$doy , bootstraps = 100)
#'
#' # note low number of bootstraps for quick processing speed
#'
#' @describeIn mean_ci Estimates CIs around a mean percentile estimate using
#' non-parametric bootstrapping from the boot package
#' @export
mean_ci <- function(observations, bootstraps = 100000,
conf = 0.95, type = 'bca'){
meanfun <- function(data, i){
d <- data[i]
return(mean(d))
}
estimate_ci(observations, .f = meanfun, n_boots = bootstraps,
conf = conf, type = type)
}
r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
data(inat_examples)
r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
mean_ci(observations = r_hirta$doy , bootstraps = 100)
quantile_ci <- function(observations, percentile, bootstraps = 100000,
conf = 0.95, type = 'bca'){
quantilefun <- function(data, i){
d <- data[i]
return(stats::quantile(d, probs = c(percentile)))
}
estimate_ci(observations, .f = quantilefun, n_boots = bootstraps,
conf = conf, type = type)
}
data(inat_examples)
s_cybele <- subset(inat_examples, scientific_name == "Speyeria cybele")
quantile_ci(observations = s_cybele$doy, percentile = 0.1, bootstraps = 100)
#' @param parallelize The type of parallel operation to be used (if any). If
#' missing, the default is that no parallelization will occur. Parallelization
#' options are "multicore" and "snow"
#' @param ncpus An integer that represents the number of processes to be
#' used in parallel operation.
#' @param cl An optional parallel or snow cluster for use if parallel = "snow".
#' If not supplied, a cluster on the local machine is created for
#' the duration of the boot call.
#' @return A data frame with estimate, and the lower and upper points of its confidence interval
#'
estimate_ci <- function(observations, .f, n_boots,
parallelize = "no",
ncpus = getOption("boot.ncpus", 1L),
cl = NULL,
type = "bca", conf = 0.95){
bootstrap <- boot::boot(observations, .f, R = n_boots,
parallel = parallelize,
ncpus = ncpus, cl = cl)
boot_ci <- tryCatch(boot::boot.ci(bootstrap, conf = conf, type = type),
error = function(e) NA)
if(is.na(boot_ci))
return(data.frame(estimate = bootstrap$t0, low_ci = NA, high_ci = NA))
if(type == "bca"){
low_ci <- boot_ci$bca[4]
high_ci <- boot_ci$bca[5]
} else if(type == "perc"){
low_ci <-boot_ci$percent[4]
high_ci <- boot_ci$percent[5]
} else if(type == "norm"){
low_ci <- boot_ci$normal[4]
high_ci <- boot_ci$normal[5]
} else if(type == "basic"){
low_ci <- boot_ci$basic[4]
high_ci <- boot_ci$basic[5]
} else{
low_ci <- "Bootstrap type NA"
high_ci <- "Bootstrap type NA"
}
data.frame(estimate = bootstrap$t0, low_ci, high_ci)
}
quantile_ci <- function(observations, percentile, bootstraps = 100000,
conf = 0.95, type = 'bca'){
quantilefun <- function(data, i){
d <- data[i]
return(stats::quantile(d, probs = c(percentile)))
}
phenesse::estimate_ci(observations, .f = quantilefun, n_boots = bootstraps,
conf = conf, type = type)
}
data(inat_examples)
s_cybele <- subset(inat_examples, scientific_name == "Speyeria cybele")
quantile_ci(observations = s_cybele$doy, percentile = 0.1, bootstraps = 100)
library(devtools)
devtools::install_github(repo = "mbelitz/phenesse")
library(phenesse)
#' @param parallelize The type of parallel operation to be used (if any). If
#' missing, the default is that no parallelization will occur. Parallelization
#' options are "multicore" and "snow"
#' @param ncpus An integer that represents the number of processes to be
#' used in parallel operation.
#' @param cl An optional parallel or snow cluster for use if parallel = "snow".
#' If not supplied, a cluster on the local machine is created for
#' the duration of the boot call.
#' @return A data frame with estimate, and the lower and upper points of its confidence interval
#'
estimate_ci <- function(observations, .f, n_boots,
parallelize = "no",
ncpus = getOption("boot.ncpus", 1L),
cl = NULL,
type = "bca", conf = 0.95){
bootstrap <- boot::boot(observations, .f, R = n_boots,
parallel = parallelize,
ncpus = ncpus, cl = cl)
boot_ci <- tryCatch(boot::boot.ci(bootstrap, conf = conf, type = type),
error = function(e) NA)
if(is.na(boot_ci))
return(data.frame(estimate = bootstrap$t0, low_ci = NA, high_ci = NA))
if(type == "bca"){
low_ci <- boot_ci$bca[4]
high_ci <- boot_ci$bca[5]
} else if(type == "perc"){
low_ci <-boot_ci$percent[4]
high_ci <- boot_ci$percent[5]
} else if(type == "norm"){
low_ci <- boot_ci$normal[4]
high_ci <- boot_ci$normal[5]
} else if(type == "basic"){
low_ci <- boot_ci$basic[4]
high_ci <- boot_ci$basic[5]
} else{
low_ci <- "Bootstrap type NA"
high_ci <- "Bootstrap type NA"
}
data.frame(estimate = bootstrap$t0, low_ci, high_ci)
}
r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
mean_ci(observations = r_hirta$doy , bootstraps = 100)
mean_ci(observations = r_hirta$doy , bootstraps = 1000)
mean_ci(observations = r_hirta$doy , bootstraps = 10000)
mean_ci(observations = r_hirta$doy , bootstraps = 100000)
mean(r_hirta$doy)
str(r_hirta$doy)
document()
document()
document()
devtools::release()
check()
document()
check()
check_rhub()
r_hirta <- subset(inat_examples, scientific_name == "Rudbeckia hirta")
mean_ci(observations = r_hirta$doy , bootstraps = 100)
#' @param parallelize The type of parallel operation to be used (if any). If
#' missing, the default is that no parallelization will occur. Parallelization
#' options are "multicore" and "snow"
#' @param ncpus An integer that represents the number of processes to be
#' used in parallel operation.
#' @param cl An optional parallel or snow cluster for use if parallel = "snow".
#' If not supplied, a cluster on the local machine is created for
#' the duration of the boot call.
#' @return A data frame with estimate, and the lower and upper points of its confidence interval
#' @export
estimate_ci <- function(observations, .f, n_boots,
parallelize = "no",
ncpus = getOption("boot.ncpus", 1L),
cl = NULL,
type = "bca", conf = 0.95){
bootstrap <- boot::boot(observations, .f, R = n_boots,
parallel = parallelize,
ncpus = ncpus, cl = cl)
boot_ci <- tryCatch(boot::boot.ci(bootstrap, conf = conf, type = type),
error = function(e) NA)
if(type == "bca"){
low_ci <- boot_ci$bca[4]
high_ci <- boot_ci$bca[5]
} else if(type == "perc"){
low_ci <-boot_ci$percent[4]
high_ci <- boot_ci$percent[5]
} else if(type == "norm"){
low_ci <- boot_ci$normal[4]
high_ci <- boot_ci$normal[5]
} else if(type == "basic"){
low_ci <- boot_ci$basic[4]
high_ci <- boot_ci$basic[5]
} else{
low_ci <- "Bootstrap type NA"
high_ci <- "Bootstrap type NA"
}
data.frame(estimate = bootstrap$t0, low_ci, high_ci)
}
mean_ci(observations = r_hirta$doy , bootstraps = 100)
check_rhub()
document()
check_rhub()
check_win_devel()
realse()
release()
release
release()
